{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nMI7CYxcyiUB"
      },
      "source": [
        "Before running the file Upload all your data set on your goole drive in a zip format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YjtnZQkTu6tX"
      },
      "outputs": [],
      "source": [
        "#Mount our google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "f4y_fGlmur4v"
      },
      "outputs": [],
      "source": [
        "#before running this please change the RUNTIME to GPU (Runtime -> Change runtime type -> set harware accelarotor as GPU)\n",
        "#download and unzip the data from google drive Colab environment\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "#use only file id of the link\n",
        "#Note: Below link is just an example, Not an actual link. Actual Links are in ReadMe file\n",
        "#https://drive.google.com/file/d/1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07/view?usp=sharing\n",
        "url = '1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07'\n",
        "gdd.download_file_from_google_drive(file_id = url,dest_path='./data.zip',unzip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1f40EeRuvAkO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frames [299, 299, 299, 299, 299, 299, 299, 299, 300, 299, 299, 299, 299, 300, 300, 299]\n",
            "Total number of videos:  16\n",
            "Average frame per video: 299.1875\n"
          ]
        }
      ],
      "source": [
        "#To get the average frame count \n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "#change the path accordingly\n",
        "video_files =  glob.glob('E:\\dataset/*.mp4')\n",
        "#video_files1 =  glob.glob('/content/dfdc_train_part_0/*.mp4')\n",
        "#video_files += video_files1\n",
        "frame_count = []\n",
        "for video_file in video_files:\n",
        "  cap = cv2.VideoCapture(video_file)\n",
        "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n",
        "    video_files.remove(video_file)\n",
        "    continue\n",
        "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "print(\"frames\" , frame_count)\n",
        "print(\"Total number of videos: \" , len(frame_count))\n",
        "print('Average frame per video:',np.mean(frame_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U92Ovn3JvV52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Using cached https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Collecting dlib>=19.7 (from face_recognition)\n",
            "  Downloading https://files.pythonhosted.org/packages/af/a4/226dbb659e913a4a149b35980e87e10050ea39a0dceac934e9e73cccbef1/dlib-19.24.4.tar.gz (3.3MB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Using cached https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz\n",
            "Requirement already satisfied: numpy in c:\\users\\yashg\\appdata\\roaming\\python\\python38\\site-packages (from face_recognition) (1.23.5)\n",
            "Requirement already satisfied: Click>=6.0 in c:\\users\\yashg\\appdata\\roaming\\python\\python38\\site-packages (from face_recognition) (8.1.6)\n",
            "Requirement already satisfied: Pillow in c:\\users\\yashg\\appdata\\roaming\\python\\python38\\site-packages (from face_recognition) (10.0.0)\n",
            "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\yashg\\appdata\\roaming\\python\\python38\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
            "Building wheels for collected packages: dlib\n",
            "  Building wheel for dlib (PEP 517): started\n",
            "  Building wheel for dlib (PEP 517): still running...\n",
            "  Building wheel for dlib (PEP 517): still running...\n",
            "  Building wheel for dlib (PEP 517): finished with status 'done'\n",
            "  Created wheel for dlib: filename=dlib-19.24.4-cp38-cp38-win_amd64.whl size=2854127 sha256=c008ed9553e9415d24fabe2bbc530f99b98943bd312524aba3626d3efc0007e5\n",
            "  Stored in directory: C:\\Users\\yashg\\AppData\\Local\\pip\\Cache\\wheels\\c2\\65\\f6\\765433dd472c7b1afbc897ccf9632d1deef596cd0be10933fe\n",
            "Successfully built dlib\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py): started\n",
            "  Building wheel for face-recognition-models (setup.py): finished with status 'done'\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566191 sha256=c2c956650ad7784dc866a43662972cd97dc32153ee57e74a8b0df5d810855c59\n",
            "  Stored in directory: C:\\Users\\yashg\\AppData\\Local\\pip\\Cache\\wheels\\d2\\99\\18\\59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: dlib, face-recognition-models, face-recognition\n",
            "Successfully installed dlib-19.24.4 face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 19.2.3, however version 24.0 is available.\n",
            "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
            "The syntax of the command is incorrect.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip3 install face_recognition\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmkdir \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/E:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDeepfake_detection_using_deep_learning-master\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "# to extract frame\n",
        "def frame_extract(path):\n",
        "  vidObj = cv2.VideoCapture(path) \n",
        "  success = 1\n",
        "  while success:\n",
        "      success, image = vidObj.read()\n",
        "      if success:\n",
        "          yield image\n",
        "!pip3 install face_recognition\n",
        "!mkdir '/E:\\Deepfake_detection_using_deep_learning-master'\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "from tqdm.autonotebook import tqdm\n",
        "# process the frames\n",
        "def create_face_videos(path_list,out_dir):\n",
        "  already_present_count =  glob.glob(out_dir+'*.mp4')\n",
        "  print(\"No of videos already present \" , len(already_present_count))\n",
        "  for path in tqdm(path_list):\n",
        "    out_path = os.path.join(out_dir,path.split('/')[-1])\n",
        "    file_exists = glob.glob(out_path)\n",
        "    if(len(file_exists) != 0):\n",
        "      print(\"File Already exists: \" , out_path)\n",
        "      continue\n",
        "    frames = []\n",
        "    flag = 0\n",
        "    face_all = []\n",
        "    frames1 = []\n",
        "    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n",
        "    for idx,frame in enumerate(frame_extract(path)):\n",
        "      #if(idx % 3 == 0):\n",
        "      if(idx <= 150):\n",
        "        frames.append(frame)\n",
        "        if(len(frames) == 4):\n",
        "          faces = face_recognition.batch_face_locations(frames)\n",
        "          for i,face in enumerate(faces):\n",
        "            if(len(face) != 0):\n",
        "              top,right,bottom,left = face[0]\n",
        "            try:\n",
        "              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n",
        "            except:\n",
        "              pass\n",
        "          frames = []\n",
        "    try:\n",
        "      del top,right,bottom,left\n",
        "    except:\n",
        "      pass\n",
        "    out.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sF5qiWGLvei-"
      },
      "outputs": [],
      "source": [
        "create_face_videos(video_files,'/content/drive/My Drive/FF_REAL_Face_only_data/')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
